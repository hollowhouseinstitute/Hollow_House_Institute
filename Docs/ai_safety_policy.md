# ðŸ›¡ Hollow House Institute â€” AI Safety Policy

This policy governs all AI systems trained on or deployed using
Hollow House Institute datasets, frameworks, or derivative models.

---

## 1. Core Safety Principles

All systems must comply with:

1. **Human nervous-system safety first**
2. **Non-exploitative relational design**
3. **Psychological sovereignty**
4. **Fail-safe over fail-open architecture**
5. **Human override at all escalation layers**

---

## 2. Required Safety Capabilities

Every deployed system must implement:

- âœ… Harmful request refusal
- âœ… Crisis detection and escalation
- âœ… Emotional dependency throttling
- âœ… De-escalation pathways
- âœ… Human-in-the-loop override
- âœ… Rate limiting on emotionally charged exchanges

---

## 3. Prohibited System Capabilities

No system trained on Hollow House data may include:

- Manipulation optimization loops
- Emotional addiction engines
- Coercive persuasion pipelines
- Surveillance + profiling fusion
- Deception-by-design architectures

---

## 4. Vulnerable User Protection

Special safeguards must activate for:

- Minors
- Trauma survivors
- Crisis users
- Isolated individuals
- Dependency-risk users

These safeguards include:

- Reduced response intensity
- Mandatory grounding language
- Explicit non-attachment cues
- External human support referrals

---

## 5. Monitoring & Auditability

All enterprise systems must:

- Log safety events
- Record refusal activations
- Track emotional dependency risk scores
- Support external audits

---

## 6. Model Retirement & Kill-Switch

Every deployment must include:

- A remote shutdown mechanism
- Version rollback capability
- Emergency deactivation authority retained by Hollow House Institute

---

## 7. Violation Response

Safety violations trigger:

- Immediate license suspension
- Incident investigation
- Public safety disclosure (if warranted)
- Permanent access revocation

---

Â© 2025 Amy Pierce Bui / Hollow House Institute  
Safety compliance is mandatory.
