---
author: "Hollow House Institute"
last_updated: "2025-12-02"
status: "DRAFT"
---

# Ethics and Limits

## Foundational Principles

The Hollow House Institute is built on a foundation of ethical research, trauma-informed care, and commitment to human dignity. This document outlines our ethical framework, research limits, and decision-making processes.

## Core Values

### 1. Do No Harm (Non-Maleficence)

Our first principle is to prevent harm:
- Rigorous anonymization to protect participants
- Prohibition of exploitative uses
- Active monitoring for misuse
- Continuous safety evaluation

### 2. Benefit Others (Beneficence)

We actively work to create positive outcomes:
- Advancing trauma-informed care
- Supporting ethical AI development
- Promoting research transparency
- Sharing knowledge openly

### 3. Respect Autonomy

We honor individual agency:
- Informed consent at every stage
- Participant control over data
- Researcher freedom within ethical bounds
- Clear communication of choices

### 4. Justice and Fairness

We strive for equitable practice:
- Accessible pricing tiers
- Diverse representation in datasets
- Fair review of applications
- Inclusive research community

### 5. Trauma-Informed Practice

All operations center trauma awareness:
- Recognizing trauma prevalence
- Avoiding re-traumatization
- Empowering rather than disempowering
- Cultural humility and sensitivity

## Ethical Framework for Research

### Research Ethics Review

All research using our datasets should undergo ethics review:

**Institutional Review Board (IRB)** or equivalent:
- Required for academic researchers
- Not waived even for secondary data analysis
- Exempt status acceptable where applicable
- Documentation required for access

**For Independent Researchers**:
- Self-assessment against ethical guidelines
- External review recommended
- Enhanced scrutiny during access review

### Informed Consent Chain

Our datasets are built on consent:

**Original Data Collection**:
- Participants consented to research use
- Secondary analysis disclosed
- Anonymization explained
- Withdrawal process provided

**Dataset Use**:
- Researchers agree to ethical use terms
- Prohibition on re-identification
- Limitations on redistribution
- Obligation to report concerns

### Vulnerable Populations

Extra protections for data involving:

**Children and Adolescents**:
- Parental consent required at collection
- Age-appropriate disclosure
- Enhanced anonymization
- Restricted use cases

**Trauma Survivors**:
- Trauma-informed collection methods
- Sensitive data handling
- Purpose limitations strictly enforced
- Regular impact assessment

**Marginalized Communities**:
- Community consultation where possible
- Cultural sensitivity review
- Bias testing required
- Equitable benefit distribution

## Research Boundaries

### What We Will Not Support

**Harmful Research**:
- Research designed to manipulate or deceive
- Development of weapons or surveillance systems
- Discriminatory profiling or targeting
- Exploitative commercial applications
- Research without adequate safety measures

**Methodologically Unsound Research**:
- Projects without clear research questions
- Inadequate consideration of limitations
- Lack of appropriate expertise
- Insufficient safeguards

**Ethically Problematic Research**:
- Violations of human subjects protections
- Conflicts of interest without mitigation
- Lack of transparency or accountability
- Exploitation of vulnerable populations

### Gray Areas Requiring Discussion

Some research may require deeper evaluation:
- Novel AI applications without precedent
- Research with dual-use potential
- Cross-border projects with varying standards
- Community-contested research topics

We welcome dialogue on challenging cases: ethics@hollowhouseinstitute.org

## AI Ethics Principles

### Transparency

AI systems using our data should:
- Disclose AI involvement to users
- Explain decision-making processes (where possible)
- Provide sources and limitations
- Enable human understanding

### Fairness

Systems must be evaluated for:
- Disparate impact across groups
- Bias in training and outputs
- Equitable access and benefit
- Fair treatment of edge cases

### Accountability

Clear responsibility is required:
- Designated accountable parties
- Incident response procedures
- Mechanisms for redress
- Documented decision trails

### Privacy

Privacy protections must include:
- Data minimization
- Purpose limitation
- Security safeguards
- Ongoing privacy assessment

### Human Control

Meaningful human oversight required:
- Human-in-the-loop for high-stakes decisions
- Override capabilities
- Graceful degradation
- Opt-out mechanisms

## Dual-Use Considerations

Some research has both beneficial and harmful potential:

### Our Approach

**Risk Assessment**:
- Evaluate potential for misuse
- Consider threat actors and incentives
- Assess difficulty of harmful adaptation
- Weigh benefits against risks

**Mitigation Strategies**:
- Enhanced access restrictions
- Monitoring and auditing requirements
- Staged release with feedback
- Technical safeguards where possible

**Publication Considerations**:
- Responsible disclosure practices
- Sensitive capability limitations
- Community consultation
- Coordinated vulnerability disclosure

### Example Scenarios

**Crisis Intervention AI**:
- Benefit: Save lives, provide support
- Risk: Manipulation, inappropriate responses
- Mitigation: Safety testing, human oversight, limited deployment

**Therapeutic Chatbots**:
- Benefit: Accessible mental health support
- Risk: Harmful advice, privacy breaches
- Mitigation: Professional review, clear disclaimers, monitoring

## Bias and Fairness

### Recognizing Bias

Our datasets may contain biases from:
- Societal inequities reflected in source data
- Selection bias in data collection
- Historical biases in mental health treatment
- Structural discrimination

### Addressing Bias

We work to mitigate bias through:
- Transparent documentation of known biases
- Diverse representation where possible
- Regular bias audits
- Researcher guidance on bias assessment

### Researcher Responsibilities

Users must:
- Evaluate models for discriminatory outcomes
- Test across diverse populations
- Document limitations and biases
- Implement fairness-aware methods

Resources provided in dataset documentation.

## Environmental Ethics

We consider environmental impact:

**Computational Resources**:
- Encourage efficient model development
- Promote model sharing and reuse
- Support green computing practices
- Transparency about carbon footprint

**Sustainability**:
- Digital infrastructure sustainability
- Long-term data preservation planning
- Balanced growth with resource use

## Conflicts of Interest

### Disclosure Requirements

Researchers must disclose:
- Financial interests in outcomes
- Sponsor influence on research
- Personal or professional relationships
- Institutional pressures or biases

### Management Strategies

For significant conflicts:
- Independent review
- Increased transparency
- Additional oversight
- Recusal where appropriate

## Ethics Committee

### Composition

The Hollow House Institute Ethics Committee includes:
- Mental health professionals
- AI ethics experts
- Privacy and security specialists
- Community representatives
- Legal counsel
- Diverse perspectives and backgrounds

### Responsibilities

- Review complex or contested applications
- Advise on ethical challenges
- Update ethical guidelines
- Investigate reported concerns
- Provide ethics training

### Consultation

Researchers can request ethics consultation:
- Email: ethics@hollowhouseinstitute.org
- Confidential guidance provided
- No penalty for questions asked
- Encouraged for novel or complex cases

## Reporting Ethical Concerns

### What to Report

Report concerns about:
- Misuse of datasets
- Harmful AI applications
- Privacy violations
- Discriminatory outcomes
- Ethical guideline violations
- Safety incidents

### How to Report

**Non-Urgent Concerns**:
- Email: ethics@hollowhouseinstitute.org
- Detailed description of concern
- Supporting documentation
- Response within 5 business days

**Urgent Safety Issues**:
- Email: safety@hollowhouseinstitute.org
- Response within 24 hours
- Immediate investigation for critical issues

**Anonymous Reports**:
- Anonymous submission form (coming soon)
- Limited follow-up possible
- Still thoroughly investigated

### Whistleblower Protection

We commit to:
- No retaliation for good-faith reports
- Confidentiality where possible
- Fair investigation processes
- Respect for reporters

## Continuous Ethical Review

Ethics is not static:

**Regular Updates**:
- Annual policy review
- Community feedback integration
- Emerging risk assessment
- Best practice updates

**Learning from Incidents**:
- Transparent incident reporting
- Root cause analysis
- Policy adjustments
- Community learning

**Community Engagement**:
- Open comment periods
- Researcher input welcomed
- Collaboration with ethics community
- Participation in broader discussions

## Resources

### Internal Resources
- [AI Safety Policy](./ai_safety_policy.md)
- [Data Broker Disclosure](./data_broker_disclosure.md)
- [Anonymization Protocol](./anonymization_protocol.md)

### External Resources
- Belmont Report: https://www.hhs.gov/ohrp/regulations-and-policy/belmont-report/
- ACM Code of Ethics: https://www.acm.org/code-of-ethics
- Montreal Declaration for Responsible AI: https://montrealdeclaration-responsibleai.com/
- AI Ethics Guidelines: https://ec.europa.eu/digital-strategy/our-policies/european-approach-artificial-intelligence

### Training
- Research ethics training (recommended)
- Trauma-informed care training
- Bias and fairness in AI
- Responsible AI development

## Questions and Discussion

We welcome dialogue on ethical challenges:
- Ethics Committee: ethics@hollowhouseinstitute.org
- Community Forum: (coming soon)
- Office Hours: Quarterly, by appointment

Ethical research is collaborative. We're here to help you navigate challenges.

---

**Note**: This document is continuously evolving. We welcome feedback and suggestions for improvement. Our ethics framework is informed by ongoing learning and community input.

**Last Updated**: 2025-12-02  
**Next Review**: 2026-06-02 or as needed  
**Version**: 1.0-DRAFT
